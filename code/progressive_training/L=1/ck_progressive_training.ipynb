{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tqdm import auto as tqdm\n",
    "from functools import lru_cache\n",
    "\n",
    "import pickle \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(a, axis=None):\n",
    "    return a / np.linalg.norm(a, axis=axis, keepdims=True)\n",
    "\n",
    "@lru_cache()\n",
    "def make_mnist_data(P=5000, d=20, P_test=None):\n",
    "    # Load data from https://www.openml.org/d/554\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    X_raw, y_raw = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "    if P_test is None:\n",
    "        P_test = P\n",
    "\n",
    "    X = X_raw[:P+P_test]\n",
    "    y = (2*(y_raw.astype(int) % 2) - 1)[:P+P_test].reshape(-1)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=P_test, random_state=42)\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components = d)\n",
    "    pca = pca.fit(X_train)\n",
    "    \n",
    "    X_train = pca.transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "\n",
    "    # project to hyper-sphere of radius sqrt(d)\n",
    "    X_train = np.sqrt(d) * normalize(X_train, axis=1)\n",
    "    X_test = np.sqrt(d) * normalize(X_test, axis=1)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = make_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump((X_train, X_test, y_train, y_test), open('mnist.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_CK_model(N, loss='squared_hinge', optimizer='adam'):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(d, name='inputs'),\n",
    "        tf.keras.layers.Dense(N, use_bias=False, activation='tanh', name='intermediate'),\n",
    "        tf.keras.layers.Dense(1, use_bias=False, name='outputs')\n",
    "    ])\n",
    "    def accuracy(y_true, y_pred):\n",
    "        return tf.reduce_mean(tf.cast(y_true*y_pred > 0, float))\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "        Allows for logarithmically spaced model saving and checkpointing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filepath, save_every=1, logarithmic=False):\n",
    "        self.filepath = filepath\n",
    "        self.save_every = save_every\n",
    "        self.logarithmic = logarithmic\n",
    "        self.last_checkpoint_epoch = 0\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self._save_model('MODEL', weights_only=False)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epoch = epoch\n",
    "        \n",
    "        if self.logarithmic:\n",
    "            save_this_epoch = (epoch >= self.last_checkpoint_epoch * 10**self.save_every)\n",
    "        else:\n",
    "            save_this_epoch = (epoch >= self.last_checkpoint_epoch + self.save_every)\n",
    "            \n",
    "        if save_this_epoch:\n",
    "            self.last_checkpoint_epoch = epoch\n",
    "            self._save_model(f'checkpoint_{epoch}.ckpt', weights_only=True)\n",
    "            \n",
    "    def on_train_end(self, logs=None):\n",
    "        self._save_model(f'checkpoint_{self.epoch}.ckpt', weights_only=True)\n",
    "            \n",
    "    def _save_model(self, filename, weights_only=True):\n",
    "        filepath = os.path.join(self.filepath, filename)\n",
    "        if weights_only:\n",
    "            self.model.save_weights(filepath, overwrite=True)\n",
    "        else:\n",
    "            self.model.save(filepath, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 5000\n",
    "d = 20\n",
    "X_train, X_test, y_train, y_test = make_mnist_data(P=P, d=d)\n",
    "\n",
    "N = int(1.1*P)\n",
    "model_directory = f'checkpoints/P_{P}-d_{d}-N_{N}_mnist'\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope():\n",
    "    model = make_CK_model(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = min(1024, P//2)\n",
    "n_steps = int(1e6)\n",
    "n_saves = 100\n",
    "\n",
    "batches_per_epoch = P//batch_size\n",
    "epochs = n_steps//batches_per_epoch\n",
    "\n",
    "tqdm_callback = tfa.callbacks.TQDMProgressBar(show_epoch_progress=False)\n",
    "save_callback = SaveCallback(model_directory, logarithmic=True, save_every=np.log10(epochs)/(n_saves))\n",
    "\n",
    "result = model.fit(X_train, y_train, epochs = epochs, batch_size=batch_size, verbose=0, callbacks=[tqdm_callback, save_callback])\n",
    "\n",
    "pickle.dump(result, open(os.path.join(model_directory, 'result.pkl'), 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha",
   "language": "python",
   "name": "alpha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "def smooth(x, y, h=1):\n",
    "    K = np.exp(-distance_matrix(x.values.reshape(-1,1), x.values.reshape(-1,1))**2/(2*h))\n",
    "    return (K@y) / (K@np.ones_like(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pickle.load(open('../L=1/mnist.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load(open('results.pkl', 'rb'))\n",
    "result_df = pd.DataFrame.from_dict(results)\n",
    "\n",
    "force = lambda y,f: 1 - y*f\n",
    "loss = lambda y,f: np.mean(np.maximum(0, force(y,f))**2, -1)\n",
    "N_del = lambda y,f: np.sum(force(y,f) >= 0, -1)\n",
    "\n",
    "result_df['test_loss'] = result_df.y_test_hat.apply(lambda f: loss(y_test, f))\n",
    "result_df['train_loss'] = result_df.y_train_hat.apply(lambda f: loss(y_train, f))\n",
    "result_df['N_del'] = result_df.y_train_hat.apply(lambda f: N_del(y_train, f))\n",
    "\n",
    "result_df['P/N'] = result_df['P']/result_df['N']\n",
    "result_df['N_del/N'] = result_df['N_del']/result_df['N']\n",
    "\n",
    "result_df['P/h'] = result_df['P']/result_df['h']\n",
    "result_df['N_del/h'] = result_df['N_del']/result_df['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_cutoff = 1e-2\n",
    "\n",
    "N_star = result_df.groupby('step').apply(lambda df: df.query('(train_loss > @star_cutoff)')['N'].max())\n",
    "result_df['N_star'] = result_df['step'].map(N_star)\n",
    "\n",
    "h_star = result_df.groupby('step').apply(lambda df: df.query('(train_loss > @star_cutoff)')['h'].max())\n",
    "result_df['h_star'] = result_df['step'].map(h_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mcolors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list(\n",
    "    'Mei2019', \n",
    "    np.array([\n",
    "        (243, 232, 29),\n",
    "        (245, 173, 47),\n",
    "        (140, 193, 53),\n",
    "        (50,  191, 133),\n",
    "        (23,  167, 198),\n",
    "        (36,  123, 235),\n",
    "        (53,  69,  252),\n",
    "        (52,  27,  203)\n",
    "    ])/255., \n",
    "    N=256\n",
    ")\n",
    "\n",
    "# cmap = cc.m_bmy\n",
    "\n",
    "gradient = np.linspace(0, 1, 256)\n",
    "gradient = np.vstack((gradient, gradient))\n",
    "fig = plt.figure(figsize=(6,.5))\n",
    "img = plt.imshow(gradient, aspect='auto', cmap=cmap)\n",
    "title = plt.title('Colormap stolen from Mei2019')\n",
    "\n",
    "norm=mcolors.LogNorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 11\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "BIGGEST_SIZE = 15\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGEST_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "by = 'step'\n",
    "x_expr = 'h/P'\n",
    "y_expr = 'train_loss'\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "by_vals = np.array(sorted(result_df.eval(by).unique(), reverse=False))[::5][::-1] #[[0, 20, 30, 40, 50, 60, 75, 88]]\n",
    "#random zorder helps with visual clarity \n",
    "extremes = by_vals[[0, -1]]\n",
    "by_vals = by_vals[1:-1]\n",
    "by_vals = np.random.choice(by_vals, size=len(by_vals), replace=False)\n",
    "by_vals = np.append(by_vals, extremes)\n",
    "norm.autoscale(by_vals)\n",
    "\n",
    "for val in by_vals: #[::-1]:\n",
    "    color = cmap(norm(val))\n",
    "    \n",
    "    data = result_df.query(f'{by} == @val')\n",
    "    data = data.iloc[np.argsort(data.eval(x_expr))]\n",
    "    \n",
    "    x = data.eval(x_expr)\n",
    "    y = data.eval(y_expr)\n",
    "    plt.scatter(x, y, c=data.eval(by), cmap=cmap, norm=norm, alpha=.7)\n",
    "    \n",
    "    y_sm = smooth(np.log(x), y, .001)\n",
    "    plt.plot(x, y_sm, color=color, ls=':', zorder=-1)\n",
    "\n",
    "plt.colorbar(sm, label='Training Steps')\n",
    "plt.xlabel(x_expr)\n",
    "plt.ylabel(y_expr)\n",
    "\n",
    "# plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# plt.axhline(star_cutoff, c='k', ls=':')\n",
    "\n",
    "plt.xlabel(r\"$h/P$\")\n",
    "plt.ylabel(r\"Train $\\mathcal{L}$\")\n",
    "# plt.title('L=1')\n",
    "fig.savefig('plots/h_P_vs_train_loss_L=2_linear.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "by = 'step'\n",
    "x_expr = 'h/P'\n",
    "y_expr = 'train_loss'\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "by_vals = np.array(sorted(result_df.eval(by).unique(), reverse=False))[::5][::-1] #[[0, 20, 30, 40, 50, 60, 75, 88]]\n",
    "#random zorder helps with visual clarity \n",
    "extremes = by_vals[[0, -1]]\n",
    "by_vals = by_vals[1:-1]\n",
    "by_vals = np.random.choice(by_vals, size=len(by_vals), replace=False)\n",
    "by_vals = np.append(by_vals, extremes)\n",
    "norm.autoscale(by_vals)\n",
    "\n",
    "for val in by_vals: #[::-1]:\n",
    "    color = cmap(norm(val))\n",
    "    \n",
    "    data = result_df.query(f'{by} == @val')\n",
    "    data = data.iloc[np.argsort(data.eval(x_expr))]\n",
    "    \n",
    "    x = data.eval(x_expr)\n",
    "    y = data.eval(y_expr)\n",
    "    plt.scatter(x, y, c=data.eval(by), cmap=cmap, norm=norm, alpha=.7)\n",
    "    \n",
    "    y_sm = smooth(np.log(x), y, .01)\n",
    "    plt.plot(x, y_sm, color=color, ls=':', zorder=-1)\n",
    "\n",
    "plt.colorbar(sm, label='Training Steps')\n",
    "plt.xlabel(x_expr)\n",
    "plt.ylabel(y_expr)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axhline(star_cutoff, c='k', ls=':')\n",
    "\n",
    "plt.xlabel(r\"$h/P$\")\n",
    "plt.ylabel(r\"Train $\\mathcal{L}$\")\n",
    "# plt.title('L=1')\n",
    "fig.savefig('plots/h_P_vs_train_loss_L=2_log.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "by = 'step'\n",
    "x_expr = 'h/h_star'\n",
    "y_expr = 'train_loss'\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "by_vals = np.array(sorted(result_df.eval(by).unique(), reverse=False))[::5][::-1] #[[0, 20, 30, 40, 50, 60, 75, 88]]\n",
    "#random zorder helps with visual clarity \n",
    "extremes = by_vals[[0, -1]]\n",
    "by_vals = by_vals[1:-1]\n",
    "by_vals = np.random.choice(by_vals, size=len(by_vals), replace=False)\n",
    "by_vals = np.append(by_vals, extremes)\n",
    "norm.autoscale(by_vals)\n",
    "\n",
    "for val in by_vals: #[::-1]:\n",
    "    color = cmap(norm(val))\n",
    "    \n",
    "    data = result_df.query(f'{by} == @val')\n",
    "    data = data.iloc[np.argsort(data.eval(x_expr))]\n",
    "    \n",
    "    x = data.eval(x_expr)\n",
    "    y = data.eval(y_expr)\n",
    "    plt.scatter(x, y, c=data.eval(by), cmap=cmap, norm=norm, alpha=.7)\n",
    "    \n",
    "    y_sm = smooth(np.log(x), y, .01)\n",
    "    plt.plot(x, y_sm, color=color, ls=':')#, zorder=-1)\n",
    "\n",
    "plt.colorbar(sm, label='Training Steps')\n",
    "plt.xlabel(x_expr)\n",
    "plt.ylabel(y_expr)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(1, c='k', ls='--')\n",
    "\n",
    "\n",
    "plt.xlabel(r\"$h/h^*$\")\n",
    "plt.ylabel(r\"Train $\\mathcal{L}$\")\n",
    "fig.savefig('plots/h_h_star_vs_train_loss_L=2_log.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "by = 'step'\n",
    "x_expr = 'h/P'\n",
    "y_expr = 'test_loss'\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "by_vals = np.array(sorted(result_df.eval(by).unique(), reverse=False))[::5][::-1] #[[0, 20, 30, 40, 50, 60, 75, 88]]\n",
    "#random zorder helps with visual clarity \n",
    "extremes = by_vals[[0, -1]]\n",
    "by_vals = by_vals[1:-1]\n",
    "by_vals = np.random.choice(by_vals, size=len(by_vals), replace=False)\n",
    "by_vals = np.append(by_vals, extremes)\n",
    "norm.autoscale(by_vals)\n",
    "\n",
    "for val in by_vals: #[::-1]:\n",
    "    color = cmap(norm(val))\n",
    "    \n",
    "    data = result_df.query(f'{by} == @val')\n",
    "    data = data.iloc[np.argsort(data.eval(x_expr))]\n",
    "    \n",
    "    x = data.eval(x_expr)\n",
    "    y = data.eval(y_expr)\n",
    "    plt.scatter(x, y, c=data.eval(by), cmap=cmap, norm=norm, alpha=.7)\n",
    "    \n",
    "    y_sm = smooth(np.log(x), y, .0001)\n",
    "    plt.plot(x, y_sm, color=color, ls=':', zorder=-1)\n",
    "\n",
    "plt.colorbar(sm, label='Training Steps')\n",
    "plt.xlabel(x_expr)\n",
    "plt.ylabel(y_expr)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# plt.axhline(5e-2, c='k')#, ls=':')\n",
    "\n",
    "plt.xlabel(r\"$h/P$\")\n",
    "plt.ylabel(r\"Test $\\mathcal{L}$\")\n",
    "fig.savefig('plots/h_P_vs_test_loss_L=2_log.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "by = 'step'\n",
    "x_expr = 'h/h_star'\n",
    "y_expr = 'test_loss'\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "by_vals = np.array(sorted(result_df.eval(by).unique(), reverse=False))[::5][::-1] #[[0, 20, 30, 40, 50, 60, 75, 88]]\n",
    "#random zorder helps with visual clarity \n",
    "extremes = by_vals[[0, -1]]\n",
    "by_vals = by_vals[1:-1]\n",
    "by_vals = np.random.choice(by_vals, size=len(by_vals), replace=False)\n",
    "by_vals = np.append(by_vals, extremes)\n",
    "norm.autoscale(by_vals)\n",
    "\n",
    "for val in by_vals: #[::-1]:\n",
    "    color = cmap(norm(val))\n",
    "    \n",
    "    data = result_df.query(f'{by} == @val')\n",
    "    data = data.iloc[np.argsort(data.eval(x_expr))]\n",
    "    \n",
    "    x = data.eval(x_expr)\n",
    "    y = data.eval(y_expr)\n",
    "    plt.scatter(x, y, c=data.eval(by), cmap=cmap, norm=norm, alpha=.7)\n",
    "    \n",
    "    y_sm = smooth(np.log(x), y, .001)\n",
    "    plt.plot(x, y_sm, color=color, ls=':', zorder=-1)\n",
    "    \n",
    "plt.colorbar(sm, label='Training Steps')\n",
    "plt.xlabel(x_expr)\n",
    "plt.ylabel(y_expr)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# plt.xlim(0, 2)\n",
    "plt.axvline(1, c='k', ls='--')\n",
    "\n",
    "plt.xlabel(r\"$h/h^*$\")\n",
    "plt.ylabel(r\"Test $\\mathcal{L}$\")\n",
    "fig.savefig('plots/h_h_star_vs_test_loss_L=2_log.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "by = 'step'\n",
    "x_expr = 'h/h_star'\n",
    "y_expr = 'N_del/h'\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "by_vals = np.array(sorted(result_df.eval(by).unique(), reverse=False))[::5][::-1] #[[0, 20, 30, 40, 50, 60, 75, 88]]\n",
    "#random zorder helps with visual clarity \n",
    "extremes = by_vals[[0, -1]]\n",
    "by_vals = by_vals[1:-1]\n",
    "by_vals = np.random.choice(by_vals, size=len(by_vals), replace=False)\n",
    "by_vals = np.append(by_vals, extremes)\n",
    "norm.autoscale(by_vals)\n",
    "\n",
    "for val in by_vals: #[::-1]:\n",
    "    color = cmap(norm(val))\n",
    "    \n",
    "    data = result_df.query(f'{by} == @val')\n",
    "    data = data.iloc[np.argsort(data.eval(x_expr))]\n",
    "    \n",
    "    x = data.eval(x_expr)\n",
    "    y = data.eval(y_expr)\n",
    "    plt.scatter(x, y, c=data.eval(by), cmap=cmap, norm=norm, alpha=.7)\n",
    "    \n",
    "#     y_sm = smooth(np.log(x), y, .001)\n",
    "#     plt.plot(x, y_sm, color=color, ls=':')\n",
    "\n",
    "plt.colorbar(sm, label='Training Steps')\n",
    "plt.xlabel(x_expr)\n",
    "plt.ylabel(y_expr)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# plt.xlim(0, 2)\n",
    "plt.axvline(1, c='k', ls='--', alpha=.7)\n",
    "plt.axhline(1, c='k', ls='--', alpha=.7)\n",
    "\n",
    "\n",
    "plt.xlabel(r\"$h/h^*$\")\n",
    "plt.ylabel(r\"$N_\\Delta/h$\")\n",
    "fig.savefig('plots/h_h_star_vs_N_del_h_L=2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "# by = 'step'\n",
    "x_expr = 'h/h_star'\n",
    "y_expr = 'N_del/N'\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "# by_vals = np.array(sorted(result_df.eval(by).unique(), reverse=False))[::5][::-1] #[[0, 20, 30, 40, 50, 60, 75, 88]]\n",
    "# norm.autoscale(by_vals)\n",
    "\n",
    "for val in by_vals: #[::-1]:\n",
    "    color = cmap(norm(val))\n",
    "    \n",
    "    data = result_df.query(f'{by} == @val')\n",
    "    data = data.iloc[np.argsort(data.eval(x_expr))]\n",
    "    \n",
    "    x = data.eval(x_expr)\n",
    "    y = data.eval(y_expr)\n",
    "    plt.scatter(x, y, c=data.eval(by), cmap=cmap, norm=norm, alpha=.7)\n",
    "    \n",
    "#     y_sm = smooth(np.log(x), y, .001)\n",
    "#     plt.plot(x, y_sm, color=color, ls=':')\n",
    "\n",
    "plt.colorbar(sm, label='Training Steps')\n",
    "plt.xlabel(x_expr)\n",
    "plt.ylabel(y_expr)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# plt.xlim(0, 2)\n",
    "plt.axvline(1, c='k', ls='--', alpha=.7)\n",
    "plt.axhline(1, c='k', ls='--', alpha=.7)\n",
    "\n",
    "\n",
    "plt.xlabel(r\"$h/h^*$\")\n",
    "plt.ylabel(r\"$N_\\Delta/N$\")\n",
    "fig.savefig('plots/h_h_star_vs_N_del_N_L=2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "by = 'step'\n",
    "x_expr = 'train_loss'\n",
    "y_expr = 'N_del/h'\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "by_vals = np.array(sorted(result_df.eval(by).unique(), reverse=False))[::5][::-1] #[[0, 20, 30, 40, 50, 60, 75, 88]]\n",
    "#random zorder helps with visual clarity \n",
    "extremes = by_vals[[0, -1]]\n",
    "by_vals = by_vals[1:-1]\n",
    "by_vals = np.random.choice(by_vals, size=len(by_vals), replace=False)\n",
    "by_vals = np.append(by_vals, extremes)\n",
    "norm.autoscale(by_vals)\n",
    "\n",
    "for val in by_vals: #[::-1]:\n",
    "    color = cmap(norm(val))\n",
    "    \n",
    "    data = result_df.query(f'{by} == @val')\n",
    "    data = data.iloc[np.argsort(data.eval(x_expr))]\n",
    "    \n",
    "    x = data.eval(x_expr)\n",
    "    y = data.eval(y_expr)\n",
    "    plt.scatter(x, y, c=data.eval(by), cmap=cmap, norm=norm, alpha=.7)\n",
    "    \n",
    "#     y_sm = smooth(np.log(x), y, .001)\n",
    "#     plt.plot(x, y_sm, color=color, ls=':')\n",
    "\n",
    "plt.colorbar(sm, label='Training Steps')\n",
    "plt.xlabel(x_expr)\n",
    "plt.ylabel(y_expr)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# plt.xlim(0, 2)\n",
    "plt.axhline(1, c='k', ls='--', alpha=.7)\n",
    "\n",
    "\n",
    "plt.xlabel(r\"Train $\\mathcal{L}$\")\n",
    "plt.ylabel(r\"$N_\\Delta/h$\")\n",
    "# fig.savefig('plots/h_h_star_vs_N_del_h_L=1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "by = 'step'\n",
    "x_expr = 'train_loss'\n",
    "y_expr = 'N_del/N'\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "by_vals = np.array(sorted(result_df.eval(by).unique(), reverse=False))[::5][::-1] #[[0, 20, 30, 40, 50, 60, 75, 88]]\n",
    "#random zorder helps with visual clarity \n",
    "extremes = by_vals[[0, -1]]\n",
    "by_vals = by_vals[1:-1]\n",
    "by_vals = np.random.choice(by_vals, size=len(by_vals), replace=False)\n",
    "by_vals = np.append(by_vals, extremes)\n",
    "norm.autoscale(by_vals)\n",
    "\n",
    "for val in by_vals: #[::-1]:\n",
    "    color = cmap(norm(val))\n",
    "    \n",
    "    data = result_df.query(f'{by} == @val')\n",
    "    data = data.iloc[np.argsort(data.eval(x_expr))]\n",
    "    \n",
    "    x = data.eval(x_expr)\n",
    "    y = data.eval(y_expr)\n",
    "    plt.scatter(x, y, c=data.eval(by), cmap=cmap, norm=norm, alpha=.7)\n",
    "    \n",
    "#     y_sm = smooth(np.log(x), y, .001)\n",
    "#     plt.plot(x, y_sm, color=color, ls=':')\n",
    "\n",
    "plt.colorbar(sm, label='Training Steps')\n",
    "plt.xlabel(x_expr)\n",
    "plt.ylabel(y_expr)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# plt.xlim(0, 2)\n",
    "plt.axhline(1, c='k', ls='--', alpha=.7)\n",
    "\n",
    "\n",
    "plt.xlabel(r\"Train $\\mathcal{L}$\")\n",
    "plt.ylabel(r\"$N_\\Delta/N$\")\n",
    "# fig.savefig('plots/h_h_star_vs_N_del_h_L=1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "# by = 'step'\n",
    "x_expr = 'N_del/h'\n",
    "y_expr = 'test_loss'\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "# by_vals = np.array(sorted(result_df.eval(by).unique(), reverse=False))[::5][::-1] #[[0, 20, 30, 40, 50, 60, 75, 88]]\n",
    "# norm.autoscale(by_vals)\n",
    "\n",
    "for val in by_vals: #[::-1]:\n",
    "    color = cmap(norm(val))\n",
    "    \n",
    "    data = result_df.query(f'{by} == @val')\n",
    "    data = data.iloc[np.argsort(data.eval(x_expr))]\n",
    "    \n",
    "    x = data.eval(x_expr)\n",
    "    y = data.eval(y_expr)\n",
    "    plt.scatter(x, y, c=data.eval(by), cmap=cmap, norm=norm, alpha=.7)\n",
    "    \n",
    "    y_sm = y #smooth(np.log(x), y, .0001)\n",
    "    plt.plot(x, y_sm, color=color, ls=':')\n",
    "\n",
    "plt.colorbar(sm, label='Training Steps')\n",
    "plt.xlabel(x_expr)\n",
    "plt.ylabel(y_expr)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# plt.xlim(0, 2)\n",
    "plt.axvline(1, c='k', ls='--', alpha=.7)\n",
    "# plt.axhline(1, c='k', ls='--', alpha=.7)\n",
    "\n",
    "\n",
    "# plt.xlabel(r\"$h/h^*$\")\n",
    "# plt.ylabel(r\"$N_\\Delta/N$\")\n",
    "# fig.savefig('plots/h_h_star_vs_N_del_N_L=1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "# by = 'step'\n",
    "x_expr = 'N_del/N'\n",
    "y_expr = 'test_loss'\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "# by_vals = np.array(sorted(result_df.eval(by).unique(), reverse=False))[::5][::-1] #[[0, 20, 30, 40, 50, 60, 75, 88]]\n",
    "# norm.autoscale(by_vals)\n",
    "\n",
    "for val in by_vals: #[::-1]:\n",
    "    color = cmap(norm(val))\n",
    "    \n",
    "    data = result_df.query(f'{by} == @val')\n",
    "    data = data.iloc[np.argsort(data.eval(x_expr))]\n",
    "    \n",
    "    x = data.eval(x_expr)\n",
    "    y = data.eval(y_expr)\n",
    "    plt.scatter(x, y, c=data.eval(by), cmap=cmap, norm=norm, alpha=.7)\n",
    "    \n",
    "    y_sm = y #smooth(np.log(x), y, .0001)\n",
    "    plt.plot(x, y_sm, color=color, ls=':')\n",
    "\n",
    "plt.colorbar(sm, label='Training Steps')\n",
    "plt.xlabel(x_expr)\n",
    "plt.ylabel(y_expr)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# plt.xlim(0, 2)\n",
    "plt.axvline(1, c='k', ls='--', alpha=.7)\n",
    "# plt.axhline(1, c='k', ls='--', alpha=.7)\n",
    "\n",
    "\n",
    "# plt.xlabel(r\"$h/h^*$\")\n",
    "# plt.ylabel(r\"$N_\\Delta/N$\")\n",
    "# fig.savefig('plots/h_h_star_vs_N_del_N_L=1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df.sort_values('step')\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['N_del']/data['h']\n",
    "y = data['test_loss']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel(r'$N_\\Delta/h$')\n",
    "plt.ylabel(r'Test $\\mathcal{L}$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['h']\n",
    "y = data['N_del']/data['h']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel('P/h')\n",
    "plt.ylabel(r'$N_\\Delta/h$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axhline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['N']\n",
    "y = data['N_del']/data['N']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel('P/N')\n",
    "plt.ylabel(r'$N_\\Delta/N$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axhline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df.query('step > 1e5')\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['N']\n",
    "y = data['N_del']/data['N']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel('P/N')\n",
    "plt.ylabel(r'$N_\\Delta/N$')\n",
    "\n",
    "\n",
    "plt.yscale('symlog', linthreshy=1)\n",
    "plt.xscale('log')\n",
    "plt.axhline(1, color='k',ls=':')\n",
    "plt.xlim(1, 500)\n",
    "plt.ylim(0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df.query('step < 5')\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['h']\n",
    "y = data['N_del']/data['h']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel('P/h')\n",
    "plt.ylabel(r'$N_\\Delta/h$')\n",
    "\n",
    "\n",
    "plt.yscale('symlog', linthreshy=1.0)\n",
    "plt.xscale('log')\n",
    "plt.axhline(1, color='k',ls=':')\n",
    "plt.xlim(1, 500)\n",
    "plt.ylim(0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df.query('step < 5')\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['h']\n",
    "y = data['N_del']/data['h']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "\n",
    "data = result_df.query('step > 1e5')\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['N']\n",
    "y = data['N_del']/data['N']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "\n",
    "\n",
    "# plt.xlabel('P/h')\n",
    "# plt.ylabel(r'$N_\\Delta/h$')\n",
    "\n",
    "\n",
    "plt.yscale('symlog', linthreshy=1.0)\n",
    "plt.xscale('log')\n",
    "plt.axhline(1, color='k',ls=':')\n",
    "plt.xlim(1, 500)\n",
    "plt.ylim(0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extremizing_rows = result_df.groupby('step').apply(lambda x: x.query('N_del/h >= 1').sort_values('N_del/h').iloc[0])\n",
    "# N_star = extremizing_rows['N']\n",
    "# result_df['N_star'] = result_df.step.map(N_star)\n",
    "\n",
    "# extremizing_rows = result_df.groupby('step').apply(lambda x: x.query('(N_del/h <= 1.)').sort_values('test_loss').iloc[-1])\n",
    "extremizing_rows = result_df.groupby('step').apply(lambda x: x.sort_values('test_loss').iloc[-1])\n",
    "N_star = extremizing_rows['N']\n",
    "result_df['N_star'] = result_df.step.map(N_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(extremizing_rows.index, extremizing_rows['N_del/h'])\n",
    "plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.axhline(1, ls=':', c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['N_star'] / data['N'] \n",
    "y = data['N_star'] * data['N_del'] / data['N']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel(r'$N/N^*$')\n",
    "plt.ylabel(r'Train $\\mathcal{L}$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['N_star'] / data['N'] \n",
    "y = data['N_del'] / data['h']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel(r'$N/N^*$')\n",
    "plt.ylabel(r'Train $\\mathcal{L}$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(1, color='k',ls=':')\n",
    "plt.axhline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df.sort_values('step')[::-20]\n",
    "norm.autoscale(data['step'].values)\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['N']/data['N_star']\n",
    "y = data['test_loss']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel(r'$N/N^*$')\n",
    "plt.ylabel(r'Test $\\mathcal{L}$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result_df['step'], result_df['N_star'], color='none')\n",
    "\n",
    "plt.scatter(result_df['step'], result_df['N_star'])\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained = result_df.query(\"step == @result_df['step'].min()\")\n",
    "trained = result_df.query(\"step == @result_df['step'].max()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'N_del/h'\n",
    "y = 'train_loss'\n",
    "\n",
    "plt.scatter(untrained[x], untrained[y])\n",
    "plt.scatter(trained[x], trained[y])\n",
    "\n",
    "for step in  sorted(result_df['step'].unique()):\n",
    "    df = result_df.query(\"step == @step\")\n",
    "    # Row with minimum value of N_del/N where train loss is non-zero and N_del/N >= 1 (underparameterized)\n",
    "    row = df.query('(train_loss > 5e-2) and (N_del/h >= 1)').sort_values('N_del/h').iloc[0]\n",
    "    plt.scatter(row[x], row[y], c='k')\n",
    "    \n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "steps = sorted(result_df['step'].unique(), reverse=False)\n",
    "norm.autoscale(steps)\n",
    "\n",
    "for i, step in enumerate(np.array(steps)): #[20::-1]): #[20::1]):\n",
    "    df = result_df.query(\"step == @step\")\n",
    "    row = df.query('(train_loss > 5e-2) and (N_del/h >= 1)').sort_values('N_del/h').iloc[0]\n",
    "\n",
    "    vals = np.sqrt(row.eigs0)\n",
    "    hist, edges = np.histogram(np.log(vals), 'sturges', density=True)\n",
    "    dx = np.mean(np.diff(edges))\n",
    "    edges = np.concatenate((edges[[0]]-dx, edges[1:]/2 + edges[:-1]/2 , edges[[-1]]+dx))\n",
    "    edges = np.exp(edges)\n",
    "    hist = np.concatenate(([0], hist, [0]))\n",
    "\n",
    "    plt.plot(edges, hist, c=sm.to_rgba(np.clip(step, norm.vmin, norm.vmax)), alpha=1.)\n",
    "plt.colorbar(sm, label='Training Steps')\n",
    "\n",
    "plt.xscale('symlog',linthreshx=1e-1)\n",
    "plt.xlim(0, None)\n",
    "plt.ylim(0, None)\n",
    "plt.xlabel(r'$\\sqrt{\\lambda}$')\n",
    "plt.ylabel(r'$P\\left(\\sqrt{\\lambda}\\right)$')\n",
    "plt.title(\"Hessian Spectrum as a Function of Training Steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap, )\n",
    "\n",
    "df = untrained.query('(N_del/h >= 1)')\n",
    "losses = np.logspace(np.log10(max(5e-2, min(df.train_loss))), np.log10(df.train_loss.max()))\n",
    "norm.autoscale(losses)\n",
    "\n",
    "last_loss = None\n",
    "for i, loss in enumerate(losses[-5::-1]): \n",
    "    row = df.query('(train_loss >= @loss) ').sort_values('N_del/h').iloc[0]\n",
    "    vals = np.sqrt(row.eigs0)\n",
    "    hist, edges = np.histogram(np.log(vals), 'sturges', density=True)\n",
    "    dx = np.mean(np.diff(edges))\n",
    "    edges = np.concatenate((edges[[0]]-dx, edges[1:]/2 + edges[:-1]/2 , edges[[-1]]+dx))\n",
    "    edges = np.exp(edges)\n",
    "    hist = np.concatenate(([0], hist, [0]))\n",
    "    \n",
    "    plt.plot(edges, hist, c=sm.to_rgba(np.clip(row.train_loss, norm.vmin, norm.vmax)), alpha=1.)\n",
    "plt.colorbar(sm, label='Train Loss')\n",
    "\n",
    "plt.xscale('symlog',linthreshx=1e-1)\n",
    "plt.xlim(0, None)\n",
    "plt.ylim(0, None)\n",
    "plt.xlabel(r'$\\sqrt{\\lambda}$')\n",
    "plt.ylabel(r'$P\\left(\\sqrt{\\lambda}\\right)$')\n",
    "plt.title(\"Hessian Spectrum as a Function of Train Loss\\nRandom Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "df = trained.query('(N_del/h >= 1)')\n",
    "losses = np.logspace(np.log10(max(5e-2, min(df.train_loss))), np.log10(df.train_loss.max()))\n",
    "norm.autoscale(losses)\n",
    "\n",
    "last_loss = None\n",
    "for i, loss in enumerate(losses[-5::-1]): \n",
    "    row = df.query('(train_loss >= @loss) ').sort_values('N_del/h').iloc[0]\n",
    "    vals = np.sqrt(row.eigs0)\n",
    "    hist, edges = np.histogram(np.log(vals), 'sturges', density=True)\n",
    "    dx = np.mean(np.diff(edges))\n",
    "    edges = np.concatenate((edges[[0]]-dx, edges[1:]/2 + edges[:-1]/2 , edges[[-1]]+dx))\n",
    "    edges = np.exp(edges)\n",
    "    hist = np.concatenate(([0], hist, [0]))\n",
    "\n",
    "    plt.plot(edges, hist, c=sm.to_rgba(np.clip(row.train_loss, norm.vmin, norm.vmax)), alpha=1.)\n",
    "plt.colorbar(sm, label='Train Loss')\n",
    "\n",
    "plt.xscale('symlog',linthreshx=1e-1)\n",
    "plt.xlim(0, None)\n",
    "plt.ylim(0, None)\n",
    "plt.xlabel(r'$\\sqrt{\\lambda}$')\n",
    "plt.ylabel(r'$P\\left(\\sqrt{\\lambda}\\right)$')\n",
    "plt.title(\"Hessian Spectrum as a Function of Train Loss\\nTrained Features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_h(N, L, d, n=1, bias=False):\n",
    "    # Modified from https://github.com/mariogeiger/nn_jamming/blob/master/constN.py\n",
    "    '''\n",
    "        For a network with: \n",
    "        \n",
    "        d input dimensionality, \n",
    "        L layers, \n",
    "        N total parameters, \n",
    "        n final outputs,\n",
    "        \n",
    "        this finds the corresponding width h \n",
    "    '''\n",
    "    assert np.all(L >= 1)\n",
    "\n",
    "    if bias:\n",
    "        # solve : N = h*(d+1) + (L-1)*h*(h+1) + n*(h+1)\n",
    "        h = -(d+L+n - ((d+L+n)**2 + 4*(L-1)*(N-n))**.5)/(2*(L-1))\n",
    "    else:\n",
    "        # solve: N = h*d + (L-1)*h*h + n*h\n",
    "        h = -((n+d) - ((n+d)**2 + 4*(L-1)*N)**.5)/(2*(L-1))\n",
    "        \n",
    "    return round(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pickle.load(open('../L=1/mnist.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load(open('results.pkl', 'rb'))\n",
    "result_df = pd.DataFrame.from_dict(results)\n",
    "result_df['h'] = find_h(result_df['N'], result_df['L'], result_df['d'])\n",
    "\n",
    "force = lambda y,f: 1 - y*f\n",
    "loss = lambda y,f: np.mean(np.maximum(0, force(y,f))**2, -1)\n",
    "N_del = lambda y,f: np.sum(force(y,f) >= 0, -1)\n",
    "\n",
    "result_df['test_loss'] = result_df.y_test_hat.apply(lambda f: loss(y_test, f))\n",
    "result_df['train_loss'] = result_df.y_train_hat.apply(lambda f: loss(y_train, f))\n",
    "result_df['N_del'] = result_df.y_train_hat.apply(lambda f: N_del(y_train, f))\n",
    "\n",
    "result_df['N/P'] = result_df['N']/result_df['P']\n",
    "result_df['P/N'] = result_df['P']/result_df['N']\n",
    "result_df['N_del/P'] = result_df['N_del']/result_df['P']\n",
    "result_df['N_del/N'] = result_df['N_del']/result_df['N']\n",
    "\n",
    "result_df['N_del/h'] = result_df['N_del']/result_df['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mcolors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list(\n",
    "    'Mei2019', \n",
    "    np.array([\n",
    "        (243, 232, 29),\n",
    "        (245, 173, 47),\n",
    "        (140, 193, 53),\n",
    "        (50,  191, 133),\n",
    "        (23,  167, 198),\n",
    "        (36,  123, 235),\n",
    "        (53,  69,  252),\n",
    "        (52,  27,  203)\n",
    "    ])/255., \n",
    "    N=256\n",
    ")\n",
    "\n",
    "# cmap = cc.m_bmy\n",
    "\n",
    "gradient = np.linspace(0, 1, 256)\n",
    "gradient = np.vstack((gradient, gradient))\n",
    "fig = plt.figure(figsize=(6,.5))\n",
    "img = plt.imshow(gradient, aspect='auto', cmap=cmap)\n",
    "title = plt.title('Colormap stolen from Mei2019')\n",
    "\n",
    "norm=mcolors.LogNorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['N_del']/data['N']\n",
    "y = data['train_loss']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel(r'$N_\\Delta/N$')\n",
    "plt.ylabel(r'Train $\\mathcal{L}$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['N_del']/data['h']\n",
    "y = data['train_loss']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel(r'$N_\\Delta/h$')\n",
    "plt.ylabel(r'Train $\\mathcal{L}$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df.sort_values('step')[::10]\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['N_del']/data['N']\n",
    "y = data['test_loss']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel(r'$N_\\Delta/N$')\n",
    "plt.ylabel(r'Test $\\mathcal{L}$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df.sort_values('step')\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['N_del']/data['h']\n",
    "y = data['test_loss']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel(r'$N_\\Delta/h$')\n",
    "plt.ylabel(r'Test $\\mathcal{L}$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['h']\n",
    "y = data['N_del']/data['h']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel('P/h')\n",
    "plt.ylabel(r'$N_\\Delta/h$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axhline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['N']\n",
    "y = data['N_del']/data['N']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel('P/N')\n",
    "plt.ylabel(r'$N_\\Delta/N$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axhline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df.query('step > 1e5')\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['N']\n",
    "y = data['N_del']/data['N']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel('P/N')\n",
    "plt.ylabel(r'$N_\\Delta/N$')\n",
    "\n",
    "\n",
    "plt.yscale('symlog', linthreshy=1.0)\n",
    "plt.xscale('log')\n",
    "plt.axhline(1, color='k',ls=':')\n",
    "plt.xlim(1, 500)\n",
    "plt.ylim(0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df.query('step < 5')\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['h']\n",
    "y = data['N_del']/data['h']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel('P/h')\n",
    "plt.ylabel(r'$N_\\Delta/h$')\n",
    "\n",
    "\n",
    "plt.yscale('symlog', linthreshy=1.0)\n",
    "plt.xscale('log')\n",
    "plt.axhline(1, color='k',ls=':')\n",
    "plt.xlim(1, 500)\n",
    "plt.ylim(0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df.query('step < 5')\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['h']\n",
    "y = data['N_del']/data['h']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "\n",
    "data = result_df.query('step > 1e5')\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['N']\n",
    "y = data['N_del']/data['N']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "\n",
    "\n",
    "# plt.xlabel('P/h')\n",
    "# plt.ylabel(r'$N_\\Delta/h$')\n",
    "\n",
    "\n",
    "plt.yscale('symlog', linthreshy=1.0)\n",
    "plt.xscale('log')\n",
    "plt.axhline(1, color='k',ls=':')\n",
    "plt.xlim(1, 500)\n",
    "plt.ylim(0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df.query('step < 5')\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['h']\n",
    "y = data['train_loss']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "\n",
    "data = result_df.query('step > 1e5')\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['P']/data['N']\n",
    "y = data['train_loss']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "\n",
    "\n",
    "# plt.xlabel('P/h')\n",
    "# plt.ylabel(r'$N_\\Delta/h$')\n",
    "\n",
    "\n",
    "plt.yscale('symlog', linthreshy=1.0)\n",
    "plt.xscale('log')\n",
    "plt.axhline(1, color='k',ls=':')\n",
    "plt.xlim(1, 500)\n",
    "plt.ylim(0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extremizing_rows = result_df.groupby('step').apply(lambda x: x.query('N_del/h >= 1').sort_values('N_del/h').iloc[0])\n",
    "# N_star = extremizing_rows['N']\n",
    "# result_df['N_star'] = result_df.step.map(N_star)\n",
    "\n",
    "# extremizing_rows = result_df.groupby('step').apply(lambda x: x.query('(N_del/h <= 1.)').sort_values('test_loss').iloc[-1])\n",
    "extremizing_rows = result_df.groupby('step').apply(lambda x: x.sort_values('test_loss').iloc[-1])\n",
    "N_star = extremizing_rows['N']\n",
    "result_df['N_star'] = result_df.step.map(N_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(extremizing_rows.index, extremizing_rows['N_del/h'])\n",
    "plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.axhline(1, ls=':', c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(extremizing_rows['N_star']/extremizing_rows['h']**2, extremizing_rows['P']/extremizing_rows['h']**2)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.axhline(1, ls=':', c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['N_star'] / data['N'] \n",
    "y = data['N_star'] * data['N_del'] / data['N']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel(r'$N/N^*$')\n",
    "plt.ylabel(r'Train $\\mathcal{L}$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['N_star'] / data['N'] \n",
    "y = data['N_del'] / data['h']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel(r'$N/N^*$')\n",
    "plt.ylabel(r'Train $\\mathcal{L}$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(1, color='k',ls=':')\n",
    "plt.axhline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "data = result_df.sort_values('step')[::-1]\n",
    "\n",
    "#invisible plot to set the limits correctly because matplotlib gets confused with log scale scatters\n",
    "x = data['N_star']/data['N']\n",
    "y = data['test_loss']\n",
    "\n",
    "plt.plot(x, y, color='none')\n",
    "plt.scatter(x, y, c=data['step'], cmap=cmap, norm=norm, alpha=.7)\n",
    "plt.colorbar(label='Training steps')\n",
    "\n",
    "plt.xlabel(r'$N/N^*$')\n",
    "plt.ylabel(r'Test $\\mathcal{L}$')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(1, color='k',ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result_df['step'], result_df['N_star'], color='none')\n",
    "\n",
    "plt.scatter(result_df['step'], result_df['N_star'])\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained = result_df.query(\"step == @result_df['step'].min()\")\n",
    "trained = result_df.query(\"step == @result_df['step'].max()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(untrained['h'], untrained['N_del'])\n",
    "plt.scatter(trained['h'], trained['N_del'])\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'N_del/N'\n",
    "y = 'train_loss'\n",
    "\n",
    "plt.scatter(untrained[x], untrained[y])\n",
    "plt.scatter(trained[x], trained[y])\n",
    "\n",
    "for step in  sorted(result_df['step'].unique()):\n",
    "    df = result_df.query(\"step == @step\")\n",
    "    # Row with minimum value of N_del/N where train loss is non-zero and N_del/N >= 1 (underparameterized)\n",
    "    row = df.query('(train_loss > 5e-2) & (N_del/h >= 1)').sort_values('N_del/h').iloc[0]\n",
    "    plt.scatter(row[x], row[y], c='k')\n",
    "    \n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "steps = sorted(result_df['step'].unique(), reverse=False)\n",
    "norm.autoscale(steps)\n",
    "\n",
    "for i, step in enumerate(np.array(steps)): #[[0,25,  30, 50, -1]]): #[20::-1]): #[20::1]):\n",
    "    df = result_df.query(\"step == @step\")\n",
    "    row = df.query('(train_loss > 5e-2) & (N_del/h >= 1)').sort_values('N_del/h').iloc[0]\n",
    "\n",
    "    vals = np.sqrt(row.eigs0)\n",
    "    hist, edges = np.histogram(np.log(vals), 'sturges', density=True)\n",
    "    dx = np.mean(np.diff(edges))\n",
    "    edges = np.concatenate((edges[[0]]-dx, edges[1:]/2 + edges[:-1]/2 , edges[[-1]]+dx))\n",
    "    edges = np.exp(edges)\n",
    "    hist = np.concatenate(([0], hist, [0]))\n",
    "\n",
    "    plt.plot(edges, hist, c=sm.to_rgba(np.clip(step, norm.vmin, norm.vmax)), alpha=1.)\n",
    "plt.colorbar(sm, label='Training Steps')\n",
    "\n",
    "plt.xscale('symlog',linthreshx=1e-1)\n",
    "plt.xlim(0, None)\n",
    "plt.ylim(0, None)\n",
    "plt.xlabel(r'$\\sqrt{\\lambda}$')\n",
    "plt.ylabel(r'$P\\left(\\sqrt{\\lambda}\\right)$')\n",
    "plt.title(\"Hessian Spectrum as a Function of Training Steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap, )\n",
    "\n",
    "df = untrained.query('(N_del/h >= 1)')\n",
    "losses = np.logspace(np.log10(max(5e-2, min(df.train_loss))), np.log(df.train_loss.max()))\n",
    "norm.autoscale(losses)\n",
    "\n",
    "last_loss = None\n",
    "for i, loss in enumerate(losses[-5::-1]): \n",
    "    row = df.query('(train_loss >= @loss) ').sort_values('N_del/h').iloc[0]\n",
    "    vals = np.sqrt(row.eigs0)\n",
    "    hist, edges = np.histogram(np.log(vals), 'sturges', density=True)\n",
    "    dx = np.mean(np.diff(edges))\n",
    "    edges = np.concatenate((edges[[0]]-dx, edges[1:]/2 + edges[:-1]/2 , edges[[-1]]+dx))\n",
    "    edges = np.exp(edges)\n",
    "    hist = np.concatenate(([0], hist, [0]))\n",
    "    \n",
    "    plt.plot(edges, hist, c=sm.to_rgba(np.clip(row.train_loss, norm.vmin, norm.vmax)), alpha=1.)\n",
    "plt.colorbar(sm, label='Train Loss')\n",
    "\n",
    "plt.xscale('symlog',linthreshx=1e-1)\n",
    "plt.xlim(0, None)\n",
    "plt.ylim(0, None)\n",
    "plt.xlabel(r'$\\sqrt{\\lambda}$')\n",
    "plt.ylabel(r'$P\\left(\\sqrt{\\lambda}\\right)$')\n",
    "plt.title(\"Hessian Spectrum as a Function of Train Loss\\nRandom Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap, )\n",
    "\n",
    "df = untrained.query('(N_del/h >= 1)').sort_values('N_del/h')\n",
    "losses = df.train_loss.values\n",
    "norm.autoscale(losses)\n",
    "\n",
    "last_loss = None\n",
    "for i, row in df[::-1].iterrows(): \n",
    "    vals = np.sqrt(row.eigs0)\n",
    "    hist, edges = np.histogram(np.log(vals), 'sturges', density=True)\n",
    "    dx = np.mean(np.diff(edges))\n",
    "    edges = np.concatenate((edges[[0]]-dx, edges[1:]/2 + edges[:-1]/2 , edges[[-1]]+dx))\n",
    "    edges = np.exp(edges)\n",
    "    hist = np.concatenate(([0], hist, [0]))\n",
    "    \n",
    "    plt.plot(edges, hist, c=sm.to_rgba(np.clip(row.train_loss, norm.vmin, norm.vmax)), alpha=1.)\n",
    "plt.colorbar(sm, label='Train Loss')\n",
    "\n",
    "plt.xscale('symlog',linthreshx=1e-1)\n",
    "plt.xlim(0, None)\n",
    "plt.ylim(0, None)\n",
    "plt.xlabel(r'$\\sqrt{\\lambda}$')\n",
    "plt.ylabel(r'$P\\left(\\sqrt{\\lambda}\\right)$')\n",
    "plt.title(\"Hessian Spectrum as a Function of Train Loss\\nRandom Features\")\n",
    "plt.yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap, )\n",
    "\n",
    "df = trained.query('(N_del/h >= 1)')\n",
    "losses = np.logspace(np.log10(max(5e-2, min(df.train_loss))), np.log(df.train_loss.max()))\n",
    "# norm.autoscale(losses)\n",
    "\n",
    "last_loss = None\n",
    "for i, loss in enumerate(losses[-5::-1]): \n",
    "    row = df.query('(train_loss >= @loss) ').sort_values('N_del/h').iloc[0]\n",
    "    vals = np.sqrt(row.eigs0)\n",
    "    hist, edges = np.histogram(np.log(vals), 'sturges', density=True)\n",
    "    dx = np.mean(np.diff(edges))\n",
    "    edges = np.concatenate((edges[[0]]-dx, edges[1:]/2 + edges[:-1]/2 , edges[[-1]]+dx))\n",
    "    edges = np.exp(edges)\n",
    "    hist = np.concatenate(([0], hist, [0]))\n",
    "\n",
    "    plt.plot(edges, hist, c=sm.to_rgba(np.clip(row.train_loss, norm.vmin, norm.vmax)), alpha=1.)\n",
    "plt.colorbar(sm, label='Train Loss')\n",
    "\n",
    "plt.xscale('symlog',linthreshx=1e-1)\n",
    "plt.xlim(0, None)\n",
    "plt.ylim(0, None)\n",
    "plt.xlabel(r'$\\sqrt{\\lambda}$')\n",
    "plt.ylabel(r'$P\\left(\\sqrt{\\lambda}\\right)$')\n",
    "plt.title(\"Hessian Spectrum as a Function of Train Loss\\nTrained Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap, )\n",
    "\n",
    "df = trained.query('(N_del/h >= 1)').sort_values('N_del/h')\n",
    "losses = df.train_loss.values\n",
    "norm.autoscale(losses)\n",
    "\n",
    "last_loss = None\n",
    "for i, row in df[::-1].iterrows(): \n",
    "    vals = np.sqrt(row.eigs0)\n",
    "    hist, edges = np.histogram(np.log(vals), 'sturges', density=True)\n",
    "    dx = np.mean(np.diff(edges))\n",
    "    edges = np.concatenate((edges[[0]]-dx, edges[1:]/2 + edges[:-1]/2 , edges[[-1]]+dx))\n",
    "    edges = np.exp(edges)\n",
    "    hist = np.concatenate(([0], hist, [0]))\n",
    "    \n",
    "    plt.plot(edges, hist, c=sm.to_rgba(np.clip(row.train_loss, norm.vmin, norm.vmax)), alpha=1.)\n",
    "plt.colorbar(sm, label='Train Loss')\n",
    "\n",
    "plt.xscale('symlog',linthreshx=1e-1)\n",
    "plt.xlim(0, None)\n",
    "plt.ylim(0, None)\n",
    "plt.xlabel(r'$\\sqrt{\\lambda}$')\n",
    "plt.ylabel(r'$P\\left(\\sqrt{\\lambda}\\right)$')\n",
    "plt.title(\"Hessian Spectrum as a Function of Train Loss\\nRandom Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import neural_tangents as nt\n",
    "from neural_tangents import stax\n",
    "\n",
    "from jax.config import config; config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from https://www.openml.org/d/554\n",
    "from sklearn.datasets import fetch_openml\n",
    "X_raw, y_raw = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 2500 #train\n",
    "P_total = int(1.5*P)\n",
    "\n",
    "X = X_raw[:P_total]\n",
    "y = (2*(y_raw.astype(int) % 2) - 1)[:P_total].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=1-P/P_total, random_state=42)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "n_components = 10\n",
    "pca = PCA(n_components = n_components)\n",
    "pca = pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# project to hyper-sphere of radius sqrt(n_components)\n",
    "X_train = np.sqrt(n_components) * X_train / np.linalg.norm(X_train, axis = 1, keepdims=True)\n",
    "X_test = np.sqrt(n_components) * X_test / np.linalg.norm(X_test, axis = 1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = n_components\n",
    "N = 2*P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_fn, apply_fn, kernel_fn_inf = stax.serial(\n",
    "    stax.Dense(N), stax.Erf(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initkey = random.PRNGKey(123)\n",
    "_, init_params = init_fn(initkey, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_fn = jit(apply_fn)\n",
    "\n",
    "train_features = apply_fn(init_params, X_train).reshape(len(X_train), -1)\n",
    "test_features = apply_fn(init_params, X_test).reshape(len(X_test), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Minimizing squared hinge loss with small regularization on the weights. \n",
    "    This gives us an L2-regularized L2-loss SVM:\n",
    "        https://www.csie.ntu.edu.tw/~cjlin/papers/liblinear.pdf#equation.A.2\n",
    "\"\"\"\n",
    "import liblinear\n",
    "import liblinearutil\n",
    "import os\n",
    "\n",
    "lamb = 1e-8\n",
    "C = 1/(P*lamb)\n",
    "\n",
    "#Primal (-s 2) is faster in our case\n",
    "model = liblinearutil.train(y_train.reshape(-1), np.array(train_features), f'-s 2 -n {os.cpu_count()} -c {C}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_label, p_acc, p_val = liblinearutil.predict(y_train.reshape(-1), np.array(train_features), model, '-q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(np.ravel(p_val), bins = 100)\n",
    "plt.title(f'Train: {p_acc[0]:.0f}% accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_label, p_acc, p_val = liblinearutil.predict(y_test.reshape(-1), np.array(test_features), model, '-q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(np.ravel(p_val), bins = 100)\n",
    "plt.title(f'Test: {p_acc[0]:.0f}% accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for sqrt_N in tqdm.tqdm(np.arange(np.sqrt(N), 0, -1)):\n",
    "    Ni = int(sqrt_N**2) #Quadratic, as if we were changing h in the NTK case\n",
    "    \n",
    "    init_fn, apply_fn, kernel_fn_inf = stax.serial(\n",
    "        stax.Dense(Ni), stax.Erf(),\n",
    "    )\n",
    "    \n",
    "    apply_fn = jit(apply_fn)\n",
    "    _, init_params = init_fn(initkey, X_train.shape)\n",
    "    \n",
    "    train_features = apply_fn(init_params, X_train).reshape(len(X_train), -1)\n",
    "    test_features = apply_fn(init_params, X_test).reshape(len(X_test), -1)\n",
    "    \n",
    "    for lamb in np.logspace(-3,-15, 5):\n",
    "        C = 1/(P*lamb)\n",
    "        model = liblinearutil.train(y_train.reshape(-1), np.array(train_features), f'-s 2 -n {os.cpu_count()} -c {C}')\n",
    "\n",
    "        train_p_label, train_p_acc, train_p_val = liblinearutil.predict(y_train.reshape(-1), np.array(train_features), model, '-q')\n",
    "        test_p_label, test_p_acc, test_p_val = liblinearutil.predict(y_test.reshape(-1), np.array(test_features), model, '-q')\n",
    "        \n",
    "        result = {\n",
    "            'N': Ni,\n",
    "            'P': P,\n",
    "            'lambda': lamb,\n",
    "            'y_train': y_train.reshape(-1),\n",
    "            'y_train_hat': np.array(train_p_val).reshape(-1),\n",
    "            'y_test': y_test.reshape(-1),\n",
    "            'y_test_hat': np.array(test_p_val).reshape(-1)\n",
    "        }\n",
    "        \n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.DataFrame(results)\n",
    "# result_df.to_json(open('results/mnist_hinge_CK.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_json(open('results/mnist_hinge_CK.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force = lambda y,f: 1 - y*f\n",
    "loss = lambda y,f: np.mean(np.maximum(0, force(y,f))**2)\n",
    "N_del = lambda y,f: np.sum(force(y,f) >= 0)\n",
    "N_correct = lambda y,f: np.sum(y*f > 0)\n",
    "N_incorrect = lambda y,f: np.sum(y*f < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['test_loss'] = np.vectorize(loss)(result_df.y_test, result_df.y_test_hat)\n",
    "result_df['train_loss'] = np.vectorize(loss)(result_df.y_train, result_df.y_train_hat)\n",
    "result_df['N_del'] = np.vectorize(N_del)(result_df.y_train, result_df.y_train_hat)\n",
    "\n",
    "result_df['N/P'] = result_df['N']/result_df['P']\n",
    "result_df['P/N'] = result_df['P']/result_df['N']\n",
    "result_df['N_del/P'] = result_df['N_del']/result_df['P']\n",
    "result_df['N_del/N'] = result_df['N_del']/result_df['N']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list(\n",
    "    'Mei2019', \n",
    "    np.array([\n",
    "        (243, 232, 29),\n",
    "        (245, 173, 47),\n",
    "        (140, 193, 53),\n",
    "        (50,  191, 133),\n",
    "        (23,  167, 198),\n",
    "        (36,  123, 235),\n",
    "        (53,  69,  252),\n",
    "        (52,  27,  203)\n",
    "    ])/255., \n",
    ")\n",
    "\n",
    "gradient = np.linspace(0, 1, 256)\n",
    "gradient = np.vstack((gradient, gradient))\n",
    "fig = plt.figure(figsize=(6,.5))\n",
    "img = plt.imshow(gradient, aspect='auto', cmap=cmap)\n",
    "title = plt.title('Colormap stolen from Mei2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "n_colors = len(result_df['lambda'].unique())\n",
    "\n",
    "#Test\n",
    "for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "    df.plot('N/P', 'test_loss', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)))\n",
    "\n",
    "#Train\n",
    "for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "    df.plot('N/P', 'train_loss', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)), ls=':')\n",
    "\n",
    "ax.legend(ncol=2, title='Test:                           Train:', title_fontsize=11)\n",
    "ax.set_ylabel('Loss')\n",
    "ax.grid(True, ls='--', alpha=.3)\n",
    "ax.set_title('Hinge loss on MNIST with CK features')\n",
    "\n",
    "fig.savefig('mnist_hinge_loss_ck_features_regularized.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "n_colors = len(result_df['lambda'].unique())\n",
    "\n",
    "#Test\n",
    "for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "    df.plot('N_del/P', 'test_loss', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)), kind='scatter')\n",
    "\n",
    "#Train\n",
    "for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "    df.plot('N_del/P', 'train_loss', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)), marker='x', kind='scatter')\n",
    "\n",
    "ax.legend(ncol=2, title='Test:                           Train:', title_fontsize=11)\n",
    "ax.set_ylabel('Loss')\n",
    "ax.grid(True, ls='--', alpha=.3)\n",
    "ax.set_title('Hinge loss on MNIST with CK features')\n",
    "\n",
    "# fig.savefig('mnist_hinge_loss_ck_features_regularized.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "n_colors = len(result_df['lambda'].unique())\n",
    "\n",
    "#Test\n",
    "for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "    df.plot('N_del/N', 'test_loss', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)), kind='scatter')\n",
    "\n",
    "#Train\n",
    "for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "    df.plot('N_del/N', 'train_loss', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)), marker='x', kind='scatter')\n",
    "\n",
    "ax.legend(ncol=2, title='Test:                           Train:', title_fontsize=11)\n",
    "ax.set_ylabel('Loss')\n",
    "ax.grid(True, ls='--', alpha=.3)\n",
    "ax.set_title('Hinge loss on MNIST with CK features')\n",
    "plt.xscale('log')\n",
    "# fig.savefig('mnist_hinge_loss_ck_features_regularized.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "n_colors = len(result_df['lambda'].unique())\n",
    "\n",
    "for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "    df.plot('train_loss', 'N_del/N', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)), marker='x', kind='scatter')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True, ls='--', alpha=.3)\n",
    "ax.set_title('Hinge loss on MNIST with CK features')\n",
    "plt.yscale('log')\n",
    "# fig.savefig('mnist_hinge_loss_ck_features_regularized.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "n_colors = len(result_df['lambda'].unique())\n",
    "\n",
    "for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "    df.plot('P/N', 'N_del/N', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)), kind='scatter')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True, ls='--', alpha=.3)\n",
    "ax.set_title('Hinge loss on MNIST with CK features')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "# fig.savefig('mnist_hinge_loss_ck_features_regularized.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "n_colors = len(result_df['lambda'].unique())\n",
    "\n",
    "for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "    df.plot('P/N', 'N_del/N', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)), kind='scatter')\n",
    "# for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "#     df.plot('P/N', 'test_loss', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)), kind='scatter')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True, ls='--', alpha=.3)\n",
    "ax.set_title('Hinge loss on MNIST with CK features')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "\n",
    "# plt.xlim(.5,10)\n",
    "# plt.ylim(.05,7)\n",
    "# fig.savefig('mnist_hinge_loss_ck_features_regularized.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "n_colors = len(result_df['lambda'].unique())\n",
    "\n",
    "#Test\n",
    "for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "    df.plot('P/N', 'test_loss', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)), kind='scatter')\n",
    "\n",
    "#Train\n",
    "for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "    df.plot('P/N', 'train_loss', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)), marker='x', kind='scatter')\n",
    "\n",
    "ax.legend(ncol=2, title='Test:                           Train:', title_fontsize=11)\n",
    "# ax.set_ylabel('Loss')\n",
    "ax.grid(True, ls='--', alpha=.3)\n",
    "ax.set_title('Hinge loss on MNIST with CK features')\n",
    "plt.xscale('log')\n",
    "# fig.savefig('mnist_hinge_loss_ck_features_regularized.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "n_colors = len(result_df['lambda'].unique())\n",
    "\n",
    "#Test\n",
    "for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "    df.plot('N_del/N', 'N_del/P', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)), kind='scatter')\n",
    "\n",
    "#Train\n",
    "for i, (lamb, df) in enumerate(result_df.groupby('lambda')):\n",
    "    df.plot('N_del/N', 'N_del/P', label='$\\log_{10}(\\lambda)$='+f'{np.log10(lamb):.1f}', ax=ax, color=cmap(float(i)/(n_colors-1)), marker='x', kind='scatter')\n",
    "\n",
    "ax.legend(ncol=2, title='Test:                           Train:', title_fontsize=11)\n",
    "# ax.set_ylabel('Loss')\n",
    "ax.grid(True, ls='--', alpha=.3)\n",
    "ax.set_title('Hinge loss on MNIST with CK features')\n",
    "plt.xscale('log')\n",
    "# fig.savefig('mnist_hinge_loss_ck_features_regularized.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
